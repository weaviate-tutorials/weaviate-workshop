{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "\n",
    "# Connect to a cloud instance of Weaviate (with WCS)\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=os.getenv(\"WORKSHOP_DEMO_URL\"),\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WORKSHOP_DEMO_KEY_ADMIN\")),\n",
    ")\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "# client = weaviate.connect_to_local()\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "# client.collections.delete(\"Wikipedia\")\n",
    "\n",
    "# Create a collection here - with Cohere as a vectorizer\n",
    "client.collections.create(\n",
    "    name=\"Wikipedia\",\n",
    "    \n",
    "    # TODO: add cohere vectorizer\n",
    "    ## use embed-multilingual-v2.0 model\n",
    "    \n",
    "    # TODO: (optional) pick a generative model (i.e. gpt-4)\n",
    "    # generative_config=Configure.Generative.,\n",
    "\n",
    "    properties=[\n",
    "        Property(name=\"text\", data_type=DataType.TEXT),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"wiki_id\", data_type=DataType.INT, skip_vectorization=True),\n",
    "        Property(name=\"url\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"lang\", data_type=DataType.TEXT, skip_vectorization=True),\n",
    "        Property(name=\"lang_id\", data_type=DataType.INT, skip_vectorization=True),\n",
    "        Property(name=\"views\", data_type=DataType.NUMBER, skip_vectorization=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def import_wiki_data(lang, lang_id, max_rows, skip_rows=0):\n",
    "    print(f\"Importing {max_rows} data items for {lang}\")\n",
    "\n",
    "    dataset = load_dataset(f\"Cohere/wikipedia-22-12-{lang}-embeddings\", split=\"train\", streaming=True)\n",
    "    dataset = dataset.skip(skip_rows)\n",
    "\n",
    "    # counter = 0\n",
    "    counter = skip_rows\n",
    "\n",
    "    wikipedia = client.collections.get(\"Wikipedia\")\n",
    "\n",
    "    with wikipedia.batch.fixed_size(batch_size=1000, concurrent_requests=4) as batch:\n",
    "        for item in tqdm(dataset, initial=skip_rows, total=max_rows):\n",
    "            vector = item[\"emb\"]\n",
    "            data_to_insert = {   \n",
    "                \"text\": item[\"text\"],\n",
    "                \"wiki_id\": item[\"wiki_id\"],\n",
    "                \"title\": item[\"title\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"views\": item[\"views\"],\n",
    "                \"lang\": lang,\n",
    "                \"lang_id\": lang_id,\n",
    "            }\n",
    "\n",
    "            # TODO: add batch insert code, insert both data_to_insert and vector\n",
    "            \n",
    "            # stop after the request number reaches = max_rows\n",
    "            counter += 1\n",
    "            if counter >= max_rows:\n",
    "                break\n",
    "    \n",
    "    # check for errors at the end\n",
    "    if (len(wikipedia.batch.failed_objects)>0):\n",
    "        print(\"Final error check\")\n",
    "        print(f\"Some errors {len(wikipedia.batch.failed_objects)}\")\n",
    "        print(wikipedia.batch.failed_objects[-1])\n",
    "    \n",
    "    print(f\"Imported {counter} items for {lang}\")\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_per_country = 10_000\n",
    "\n",
    "import_wiki_data(\"en\", 0, import_per_country, 0)\n",
    "import_wiki_data(\"de\", 1, import_per_country, 0)\n",
    "import_wiki_data(\"fr\", 2, import_per_country, 0)\n",
    "# import_wiki_data(\"es\", 3, import_per_country, 0)\n",
    "# import_wiki_data(\"it\", 4, import_per_country, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
