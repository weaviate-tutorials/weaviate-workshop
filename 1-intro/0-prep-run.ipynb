{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - make sure you can connect\n",
    "\n",
    "> `TODO` - update the host to a url of your instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "load_dotenv()\n",
    "WEAVIATE_KEY = os.getenv(\"WEAVIATE_KEY\")\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "client = weaviate.connect_to_local(\n",
    "  host=\"127.0.0.1\", # the address to the learner's instance\n",
    "  port=8080,        # the default REST port\n",
    "  grpc_port=50051,  # the default GRPC port\n",
    "  auth_credentials=Auth.api_key(WEAVIATE_KEY)\n",
    ")\n",
    "\n",
    "client.is_ready() # Expected True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the available modules - ideally you should be able to see 'generative-openai' and 'text2vec-openai'\n",
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - test your OpenAI configuration\n",
    "> `TODO: 1` - update the `host` to a url of your instance\n",
    "\n",
    "> `TODO: 2` - update the `base_url` (twice) to your OpenAI url where you host the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_URL = os.getenv(\"OPENAI_URL\")\n",
    "print(f\"OpenAI API Key: {OPENAI_API_KEY}\")\n",
    "print(f\"OpenAI URL: {OPENAI_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Connect to the local instance\n",
    "client = weaviate.connect_to_local(\n",
    "  host=\"127.0.0.1\", # the address to the learner's instance\n",
    "  port=8080,\n",
    "  grpc_port=50051,\n",
    "  auth_credentials=Auth.api_key(WEAVIATE_KEY),\n",
    "  headers={\n",
    "    \"X-OpenAI-Api-Key\": OPENAI_API_KEY\n",
    "  }\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure\n",
    "\n",
    "if client.collections.exists(\"TestCollection\"):\n",
    "    client.collections.delete(\"TestCollection\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"TestCollection\",\n",
    "    \n",
    "    # Using local ollama embedding model\n",
    "    vector_config=Configure.Vectors.text2vec_ollama(\n",
    "        model=\"nomic-embed-text\",\n",
    "        api_endpoint=OPENAI_URL\n",
    "    ),\n",
    "    \n",
    "    # Using local ollama generative model\n",
    "    generative_config=Configure.Generative.ollama(\n",
    "        model=\"qwen2.5:0.5b\",\n",
    "        api_endpoint=OPENAI_URL\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# prepare the sample data\n",
    "with open(\"./jeopardy_tiny.json\") as file:\n",
    "    data_10 = json.load(file)\n",
    "\n",
    "print(json.dumps(data_10[0:2], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection = client.collections.get(\"TestCollection\")\n",
    "test_collection.data.insert_many(data_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of objects - should be 10\n",
    "len(test_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data preview - with vectors\n",
    "test_collection = client.collections.get(\"TestCollection\")\n",
    "response = test_collection.query.fetch_objects(\n",
    "    limit=4,\n",
    "    include_vector=True\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "  print(item.properties)\n",
    "  print(item.vector, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query example â€“ it uses the OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = test_collection.query.near_text(\n",
    "  query=\"African animals\",\n",
    "  limit=2\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "  print(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = test_collection.generate.near_text(\n",
    "    query=\"African animals\",\n",
    "    limit=2,\n",
    "    single_prompt=\"Please translate {question} to german\"\n",
    ")\n",
    "\n",
    "print(\"=== Source ===\")\n",
    "for item in response.objects:\n",
    "    print(item.properties)\n",
    "    print(item.generative.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
