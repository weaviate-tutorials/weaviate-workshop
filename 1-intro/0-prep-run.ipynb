{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> should be 4.16 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - make sure you can connect\n",
    "\n",
    "> `TODO` - update the host to a url of your instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "load_dotenv()\n",
    "WEAVIATE_KEY = os.getenv(\"WEAVIATE_KEY\")\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "client = weaviate.connect_to_local(\n",
    "  host=\"127.0.0.1\", # the address to the learner's instance\n",
    "  port=8080,        # the default REST port\n",
    "  grpc_port=50051,  # the default GRPC port\n",
    "  auth_credentials=Auth.api_key(WEAVIATE_KEY)\n",
    ")\n",
    "\n",
    "client.is_ready() # Expected True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the available modules - ideally you should be able to see 'generative-openai' and 'text2vec-openai'\n",
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - test your OpenAI configuration\n",
    "> `TODO: 1` - update the `host` to a url of your instance\n",
    "\n",
    "> `TODO: 2` - update the `base_url` (twice) to your OpenAI url where you host the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "WEAVIATE_KEY = os.getenv(\"WEAVIATE_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_URL = os.getenv(\"OPENAI_URL\")\n",
    "print(f\"OpenAI API Key: {OPENAI_API_KEY[:20]}\")\n",
    "print(f\"OpenAI URL: {OPENAI_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Connect to the local instance\n",
    "client = weaviate.connect_to_local(\n",
    "  host=\"127.0.0.1\", # the address to the learner's instance\n",
    "  port=8080,\n",
    "  grpc_port=50051,\n",
    "  auth_credentials=Auth.api_key(WEAVIATE_KEY),\n",
    "  headers={\n",
    "    \"X-OpenAI-Api-Key\": OPENAI_API_KEY\n",
    "  }\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure\n",
    "\n",
    "if client.collections.exists(\"TestCollection\"):\n",
    "    client.collections.delete(\"TestCollection\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"TestCollection\",\n",
    "    \n",
    "    # Using local ollama embedding model\n",
    "    vector_config=Configure.Vectors.text2vec_openai(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        # base_url=OPENAI_URL\n",
    "        base_url=\"https://api.openai.com\"\n",
    "    ),\n",
    "    \n",
    "    # Using local ollama generative model\n",
    "    generative_config=Configure.Generative.openai(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        base_url=\"https://api.openai.com\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# prepare the sample data\n",
    "with open(\"./jeopardy_tiny.json\") as file:\n",
    "    data_10 = json.load(file)\n",
    "\n",
    "print(json.dumps(data_10[0:2], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection = client.collections.get(\"TestCollection\")\n",
    "test_collection.data.insert_many(data_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of objects - should be 10\n",
    "len(test_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data preview - with vectors\n",
    "test_collection = client.collections.get(\"TestCollection\")\n",
    "response = test_collection.query.fetch_objects(\n",
    "    limit=4,\n",
    "    include_vector=True\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "  print(item.properties)\n",
    "  print(item.vector, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query example â€“ it uses the OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = test_collection.query.near_text(\n",
    "  query=\"African animals\",\n",
    "  limit=2\n",
    ")\n",
    "\n",
    "for item in response.objects:\n",
    "  print(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = test_collection.generate.near_text(\n",
    "    query=\"African animals\",\n",
    "    limit=2,\n",
    "    single_prompt=\"Please translate {question} to german\"\n",
    ")\n",
    "\n",
    "print(\"=== Source ===\")\n",
    "for item in response.objects:\n",
    "    print(item.properties)\n",
    "    print(item.generative.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
