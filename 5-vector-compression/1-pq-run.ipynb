{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression â€“ Load Data and compress vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Collection with PQ configuration\n",
    "\n",
    "[Docs: Product Quantization (PQ)](https://weaviate.io/developers/weaviate/configuration/compression/pq-compression)\n",
    "\n",
    "> Note: Product Quantization includes a training phase, which is required to create codebooks (codebooks are used to generate centroids for compressed vectors).<br/>\n",
    "> In other words, based on your data, it figures out how to best compress your vectors.\n",
    ">\n",
    "> The compression training starts when the collection reaches `training_limit` number of objects.<br/>\n",
    "> Before that, the vectors remain uncompressed, and search happens on uncompressed vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure\n",
    "\n",
    "client.collections.delete(\"WikiPQ\")\n",
    "\n",
    "# Create a collection here - with Cohere as a vectorizer\n",
    "client.collections.create(\n",
    "    name=\"WikiPQ\",\n",
    "\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.text2vec_openai(\n",
    "            name=\"main_vector\",\n",
    "\n",
    "            model=\"text-embedding-3-small\",\n",
    "            source_properties=['title', 'text'],\n",
    "\n",
    "            # Configure PQ\n",
    "            vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                quantizer=Configure.VectorIndex.Quantizer.pq(\n",
    "                    segments=256, # 1536/6 # new number of dimension segments\n",
    "                    training_limit=10_000  # (default 100k) number of objects needed to train the codebook\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_loader import import_wiki_data\n",
    "# import_wiki_data(client, \"WikiPQ\", 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikiPQ = client.collections.get(\"WikiPQ\")\n",
    "# wikiPQ.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.collections.delete(\"WikiPQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
